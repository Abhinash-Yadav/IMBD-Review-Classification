{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load IMDb dataset from CSV file (fetching only 1200 reviews)\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\").head(1200)\n",
        "\n",
        "# Convert sentiment labels to binary (1 for positive, 0 for negative)\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Tokenization and padding\n",
        "max_features = 10000  # Number of words to consider\n",
        "maxlen = 500  # Maximum sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(df['review'])\n",
        "sequences = tokenizer.texts_to_sequences(df['review'])\n",
        "x_data = pad_sequences(sequences, maxlen=maxlen)\n",
        "y_data = df['sentiment'].values\n",
        "\n",
        "# Split dataset into training (1000 samples) and testing (200 samples)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=200/1200, random_state=42)\n",
        "\n",
        "# Build LSTM model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=max_features, output_dim=128, input_length=maxlen),  # Embedding Layer\n",
        "    keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2),  # LSTM Layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 5  # You can increase epochs for better accuracy\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(f\"Test accuracy: {acc}\")\n",
        "\n",
        "# Function to predict sentiment of new reviews\n",
        "def predict_review(review):\n",
        "    sequence = tokenizer.texts_to_sequences([review])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=maxlen)\n",
        "    prediction = model.predict(padded_sequence)[0][0]\n",
        "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Predicted Sentiment: {sentiment} (Probability: {prediction:.4f})\")\n",
        "\n",
        "# Example Predictions\n",
        "predict_review(\"This movie was absolutely fantastic! I loved it.\")\n",
        "predict_review(\"The movie was terrible and a complete waste of time.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaqYLjbrpdru",
        "outputId": "413d8164-080e-4988-8b8b-0c677d149280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.4939 - loss: 0.6930 - val_accuracy: 0.6500 - val_loss: 0.6766\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.7792 - loss: 0.6160 - val_accuracy: 0.6400 - val_loss: 0.6243\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.8682 - loss: 0.3810 - val_accuracy: 0.7100 - val_loss: 0.5522\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.9507 - loss: 0.1951 - val_accuracy: 0.7050 - val_loss: 0.6120\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.9787 - loss: 0.0798 - val_accuracy: 0.7250 - val_loss: 0.7080\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.7590 - loss: 0.6555\n",
            "Test accuracy: 0.7250000238418579\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
            "Review: This movie was absolutely fantastic! I loved it.\n",
            "Predicted Sentiment: Negative (Probability: 0.0388)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "Review: The movie was terrible and a complete waste of time.\n",
            "Predicted Sentiment: Negative (Probability: 0.0006)\n"
          ]
        }
      ]
    }
  ]
}